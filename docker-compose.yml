version: '3.8'

services:
  llama-server:
    build:
      context: ./llama-server  # Ensure this points to the correct folder
      dockerfile: Dockerfile
      args:
        HF_TOKEN: ${HF_TOKEN}  # Pass in Hugging Face token
    container_name: llama-server
    volumes:
      - ./llama-server:/app  # Mount local files to container
    ports:
      - "5000:5000"
    restart: unless-stopped
    env_file:
      - .env  # Store email credentials securely
  ai-server:
    build:
      context: ./ai-server  # Path to the directory containing Dockerfile
      dockerfile: Dockerfile
    container_name: thunderbird-ai
    depends_on:
      - llama-server
    env_file:
      - .env  # Store email credentials securely
    ports:
      - "4000:4000"
    restart: unless-stopped